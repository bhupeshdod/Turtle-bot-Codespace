{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1\n",
    "Welcome to the Turtlebot4 Orientation Lab. Here you will learn to:\n",
    "* Read data from the robots services\n",
    "* Drive the robot around\n",
    "* Accuracy of the odometry\n",
    "\n",
    "Next, just execute the code cells below in sequence, read the comments, the output, and see what happens.\n",
    "\n",
    "Don't worry, you can modify this code as you like. First, let's confirm you know how to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text box is called a cell.\n",
    "# In this environment, a Jupyter Python Notebook, it contains Python code.\n",
    "# Click on the triangle left of this box (cell) to execute it.\n",
    "# The output will appear below.\n",
    "print(1+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Robot wrapper and initialize ROS\n",
    "While the Turtlebot4 works using ROS2, you are using a wrapper around\n",
    "ROS2 to make things more straight forward. \n",
    "\n",
    "You can inspect the wrapper by opening the file [/opt/robohub/humble/lib/python3.10/site-packages/turtlebot4_wrapper/\\_\\_init__.py](/opt/robohub/humble/lib/python3.10/site-packages/turtlebot4_wrapper/\\_\\_init__.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to uwbot-13\n",
      "Robot is reachable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine the type for the passed topic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ros2 topic echo --once /ip failed. Proceed with caution.\n",
      "ros2 topic subscription working. Everything is working as expected.\n"
     ]
    }
   ],
   "source": [
    "import turtlebot4_wrapper\n",
    "\n",
    "turtlebot4_wrapper.use_hardware()\n",
    "# turtlebot4_wrapper.use_simulation()\n",
    "\n",
    "# load ROS library\n",
    "import rclpy\n",
    "if not rclpy.ok():\n",
    "    rclpy.init()\n",
    "\n",
    "# Instantiate Wrapper. The subscribes and publishes the relevant topics and connects the actions.\n",
    "if not \"robot\" in globals():\n",
    "    robot = turtlebot4_wrapper.Robot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Read data from topics: Battery charge state\n",
    "Check Battery State. Note: 10% get you 10 minutes of runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have fresh data by waiting for a new message\n",
    "robot.battery_state_future = rclpy.Future()\n",
    "robot.spin_until_future_completed(robot.battery_state_future)\n",
    "\n",
    "# Pretty print the contents of the message\n",
    "print(\"Battery {0:2.3}%, charging with {1:2.2}A\".format(\n",
    "    robot.last_battery_state_msg.percentage*100,\n",
    "    robot.last_battery_state_msg.current\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Drive the robot via teleoperation\n",
    "First, undock the robot using a preprogrammed behavior. Then open the visualization to drive the robot using buttons. After you are done, dock the robot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irobot_create_msgs.action.Undock_Result(is_docked=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.undock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.open_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You can additional move the robot with your phone:\")\n",
    "robot.open_visualization(open_url=False,mobile_layout=True,display_qrcode=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the new webpage In the foxglove visualizer, you can drive the robot with panels in the bottom right hand corner. After you are done exploring, position the robot so that it is approximately 1-2m away from the dock and is pointing towards the dock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.dock()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Drive a square shape\n",
    "In this example the robot automatically drives a square shape. While this is interesting to watch, it shows also some challenges. Before you execute this, mark the start position on the floor using tape as shown below (TODO: picture. Place your start position such that the robot has at least 0.5m space to the front and 0.5m to the left. Then execute the next cell. The code will also start a background logging process so you can analyze the data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "logging already active",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22691/756667169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_odometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make the robot think it is at position (0,0,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/odom\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/tf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/tf_static\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/scan\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set topics which should be recorded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start the background logging process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# drive the square\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cmd_vel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/robohub/humble/lib/python3.10/site-packages/turtlebot4_wrapper/__init__.py\u001b[0m in \u001b[0;36mstart_logging\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'logging_instance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logging already active\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tmp/notebook_bag_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ros2 bag record -s mcap --output \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" > /tmp/ros2_bag.log 2>&1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreexec_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: logging already active"
     ]
    }
   ],
   "source": [
    "# send_cmd_vel (forward_velocity, rotation_velocity, duration)\n",
    "robot.reset_odometry() # make the robot think it is at position (0,0,0) \n",
    "robot.configure_logging([\"/odom\",\"/tf\",\"/tf_static\",\"/scan\"]) # set topics which should be recorded\n",
    "robot.start_logging() # start the background logging process\n",
    "for iterations in range(1): # drive the square\n",
    "    robot.set_cmd_vel(0.4, 0.0, 12.) # 0.1\n",
    "    robot.set_cmd_vel(0.0, 0.5, 3.14)\n",
    "    robot.set_cmd_vel(3.9, 0.0, 8) # 0.1\n",
    "    robot.set_cmd_vel(0.0, 0.5, 3.14)\n",
    "    robot.set_cmd_vel(4.95, 0.0, 12.) # 0.1\n",
    "    robot.set_cmd_vel(0.0, 0.5, 3.14)\n",
    "    robot.set_cmd_vel(3.84, 0.0, 8) # 0.1\n",
    "    robot.set_cmd_vel(0.0, 0.5, 3.14)\n",
    "logging_dir = robot.stop_logging()\n",
    "log_data = robot.get_logging_data(logging_dir) # parse the logged data and import in python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the next cell will open the log data in the visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.open_logging_data_in_visualizer(logging_dir)\n",
    "robot.delete_logging_data(logging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data in the notebook\n",
    "print(\"Collected {} samples\".format(len(log_data['/odom'])))\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Wedge\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "# TODO: decide if x forward is really the way to go\n",
    "plt.xlim([-1.5,0.2])\n",
    "plt.ylim([-0.2,1.5])\n",
    "for msg in log_data['/odom'][::20]:\n",
    "    T3D = robot.convert_odom_to_transform(msg[1].pose.pose)\n",
    "    T2D = robot.reduce_transform_to_2D(T3D)\n",
    "    circ = Circle((-T2D[1,2],T2D[0,2]),0.1) # TODO: correct radius\n",
    "    circ.set_fill(False)\n",
    "    ax.add_patch(circ)\n",
    "    angle = robot.rotation_from_transform(T2D)\n",
    "    import math\n",
    "    angle = angle/math.pi*180\n",
    "    wedge = Wedge((-T2D[1,2],T2D[0,2]),0.1, angle+180+45, angle+360-45)\n",
    "    ax.add_patch(wedge)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment, please try to explain two aspect:\n",
    "* Discrepancies between the commanded robot motion and the executed one\n",
    "* Discrepancies between the measured motion and the one you observed\n",
    "Try to come up with an answer and write it in the next field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, after you are done with this lab please save this notebook. Then commit the repository and push it. Detailled instructions will follow, but this is how you submit your work in this course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Drive robot and aquire odometry\n",
    "Tape measure, tape. Optional: Laser pointer.\n",
    "\n",
    "* Tape two parallel lines `0.2m` apart on the floor. These are start and finish lines `0.2m`.\n",
    "* Place the robot at the start line\n",
    "* Read data from the Odometry topic\n",
    "* Command the robot to drive `0.2m` straight\n",
    "* Read data from the Odometry topic.\n",
    "Did the robot travel `0.2m`? Where could the error come from?\n",
    "\n",
    "Modify the experiment to investigate the behavior for rotation. Instead of the start and finish line attach a laser pointer to the base and aim it at a reference point. Command the robot to turn one full revolution.\n",
    "\n",
    "Reading:\n",
    "- Odometry sensor: TODO: find link\n",
    "- Quaternions: https://en.wikipedia.org/wiki/Quaternion#Quaternions_and_the_space_geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprogrammed behavior: Drive off the dock in a controlled way\n",
    "robot.undock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display raw data: Odometry based position\n",
    "robot.odom_future = rclpy.Future()\n",
    "pose1 = robot.spin_until_future_completed(robot.odom_future).pose.pose\n",
    "print(pose1.position)\n",
    "print(pose1.orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive with desired velocity command:\n",
    "velocity_x = 2 # in m/s\n",
    "velocity_phi = 5. # for rotation test use 0.5 rad/s\n",
    "duration = 5. # in s\n",
    "robot.set_cmd_vel(velocity_x, velocity_phi, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display raw data: Odometry based position\n",
    "robot.odom_future = rclpy.Future()\n",
    "pose2 = robot.spin_until_future_completed(robot.odom_future).pose.pose\n",
    "print(pose2.position)\n",
    "print(pose2.orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation\n",
    "print(\"Desired distance: {}\".format(velocity_x*duration))\n",
    "import numpy\n",
    "print(\"Measured distance: {}\".format(\n",
    "    numpy.sqrt( (pose1.position.x - pose2.position.x)**2 + (pose1.position.y - pose2.position.y)**2 ) ))\n",
    "\n",
    "# rotation\n",
    "import eigenpy # makes use of the Eigen C++ library ()\n",
    "def make_quaternion(q):\n",
    "    return eigenpy.Quaternion(q.w,q.x,q.y,q.z)\n",
    "print(\"Desired rotation: {}\".format(\n",
    "    velocity_phi * duration))\n",
    "print(\"Measured rotation: {}\".format(\n",
    "    make_quaternion(pose1.orientation).angularDistance(make_quaternion(pose2.orientation))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Plot Xy for manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send_cmd_vel (forward_velocity, rotation_velocity, duration)\n",
    "robot.reset_odometry() # make the robot think it is at position (0,0,0) \n",
    "robot.configure_logging([\"/odom\",\"/tf\",\"/tf_static\",\"/scan\"]) # set topics which should be recorded\n",
    "robot.start_logging() # start the background logging process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = robot.stop_logging()\n",
    "log_data = robot.get_logging_data(logging_dir) # parse the logged data and import in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot/xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data in the notebook\n",
    "print(\"Collected {} samples\".format(len(log_data['/odom'])))\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Wedge\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "# TODO: decide if x forward is really the way to go\n",
    "plt.xlim([-4,0.2])\n",
    "plt.ylim([-0.2,1.5])\n",
    "for msg in log_data['/odom'][::20]:\n",
    "    T3D = robot.convert_odom_to_transform(msg[1].pose.pose)\n",
    "    T2D = robot.reduce_transform_to_2D(T3D)\n",
    "    circ = Circle((-T2D[1,2],T2D[0,2]),0.1) # TODO: correct radius\n",
    "    circ.set_fill(False)\n",
    "    ax.add_patch(circ)\n",
    "    angle = robot.rotation_from_transform(T2D)\n",
    "    import math\n",
    "    angle = angle/math.pi*180\n",
    "    wedge = Wedge((-T2D[1,2],T2D[0,2]),0.1, angle+180+45, angle+360-45)\n",
    "    ax.add_patch(wedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lidar Scan PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot robot position from odometry\n",
    "# Use blue cross marker to designate the robot position\n",
    "pose = robot.last_odom_msg.pose.pose\n",
    "plt.plot([pose.position.x],[pose.position.y],'bx') # TODO: show robot front\n",
    "\n",
    "# not sure why but this sometimes hangs here so I pulled out the static transform manually into T_base_lidar\n",
    "# T_base_lidar = robot.get_tf_transform(\"rplidar_link\",\"base\")\n",
    "# T_base_lidar = robot.reduce_transform_to_2D(T_base_lidar)\n",
    "\n",
    "T_base_lidar = np.array([[ 2.22044605e-16, -1.00000000e+00, -4.00000000e-02],\n",
    "       [ 1.00000000e+00,  2.22044605e-16,  0.00000000e+00],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "# Plot lidar points from last message\n",
    "def plot_lidar_scan_points(msg,pose):\n",
    "    # Convert received lidar points into cartesian coordinates considering the current position from odometry\n",
    "    import numpy\n",
    "    points = [(numpy.cos(angle)*radius,numpy.sin(angle)*radius) for angle, radius \\\n",
    "              in zip(numpy.linspace(msg.angle_min,msg.angle_max,len(msg.ranges)),msg.ranges)]\n",
    "\n",
    "    T = robot.reduce_transform_to_2D(robot.convert_odom_to_transform(pose))\n",
    "    \n",
    "    # remove points which cannot be measured\n",
    "    filtered_points = filter(lambda x: numpy.isfinite(x).all(),points)\n",
    "    \n",
    "    # display points in world frame\n",
    "    transformed_points = [numpy.matmul(np.dot(T,T_base_lidar),\n",
    "        numpy.vstack([ numpy.atleast_2d(x).T,numpy.ones((1,1)) ]) ) for x in \n",
    "                          filtered_points]\n",
    "    plt.plot(\n",
    "        [x[0] for x in transformed_points],\n",
    "        [x[1] for x in transformed_points],'r.')\n",
    "\n",
    "plot_lidar_scan_points(robot.last_scan_msg,pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slam_toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty map\n",
    "map_resolution = 0.1  # Define the resolution of the map (adjust as needed)\n",
    "map_width = int(4 / map_resolution)  # Define the map width (adjust as needed)\n",
    "map_height = int(1.7 / map_resolution)  # Define the map height (adjust as needed)\n",
    "occupancy_map = [[0 for _ in range(map_width)] for _ in range(map_height)]\n",
    "\n",
    "# Plot data in the notebook\n",
    "print(\"Collected {} samples\".format(len(log_data['/odom']))\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Wedge\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xlim([-4, 0.2])\n",
    "plt.ylim([-0.2, 1.5])\n",
    "\n",
    "for msg in log_data['/odom'][::20]:\n",
    "    T3D = robot.convert_odom_to_transform(msg[1].pose.pose)\n",
    "    T2D = robot.reduce_transform_to_2D(T3D)\n",
    "    \n",
    "    # Calculate cell indices for the map\n",
    "    x_index = int((T2D[0, 2] + 4) / map_resolution)\n",
    "    y_index = int((T2D[1, 2] + 0.2) / map_resolution)\n",
    "\n",
    "    # Update the map at the corresponding cell\n",
    "    occupancy_map[y_index][x_index] = 1  # You can use different values for occupied and unoccupied cells\n",
    "\n",
    "    # Plot the robot's position on the XY plot\n",
    "    circ = Circle((-T2D[1, 2], T2D[0, 2]), 0.1)  # TODO: correct radius\n",
    "    circ.set_fill(False)\n",
    "    ax.add_patch(circ)\n",
    "    angle = robot.rotation_from_transform(T2D)\n",
    "    import math\n",
    "    angle = angle / math.pi * 180\n",
    "    wedge = Wedge((-T2D[1, 2], T2D[0, 2]), 0.1, angle + 180 + 45, angle + 360 - 45)\n",
    "    ax.add_patch(wedge)\n",
    "\n",
    "# Now, you have the occupancy map representing the robot's movement\n",
    "# You can visualize the map or save it for further analysis\n",
    "plt.figure()\n",
    "plt.imshow(occupancy_map, cmap='gray', extent=[-4, 0.2, -0.2, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/notebook_bag_1699485730'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.stop_logging()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
